{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "文字認識　MNIST kaggle",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4gqsf4YuRrGtlB+mXbzMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furusawa-ryoji/MNIST/blob/develop/%E6%96%87%E5%AD%97%E8%AA%8D%E8%AD%98%E3%80%80MNIST_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjdJaicQqmS3",
        "colab_type": "text"
      },
      "source": [
        "# kaggleの評価\n",
        "データセットは1枚の画像のピクセルが784(28*28)列で表現されている(0,1で白黒判定かどうかはまだ調べていないがおそらくそう)\n",
        "\n",
        "提出方法はIdとテストデータを予測した手書き文字の2列のCSVファイル\n",
        "\n",
        "評価方法はどれだけ予想した手書き文字が合っているかで判定(97%正答なら0.97と表示)\n",
        "一番いいのは1.00"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4LhyGFVvGcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "90ce1744-e987-45b0-f354-e6188652577e"
      },
      "source": [
        "# ZIPファイル解凍\n",
        "!unzip digit*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  digit-recognizer.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySvKYqff3obK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "28245809-cbd7-4fd4-de94-52235b5b53d4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# データの読み込み\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n",
            "(28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY83NCAjBPaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c3563ac0-94c9-40bc-f8af-fe3d4e62a4a0"
      },
      "source": [
        "# データの確認\n",
        "train_df.info"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of        label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0          1       0       0       0  ...         0         0         0         0\n",
              "1          0       0       0       0  ...         0         0         0         0\n",
              "2          1       0       0       0  ...         0         0         0         0\n",
              "3          4       0       0       0  ...         0         0         0         0\n",
              "4          0       0       0       0  ...         0         0         0         0\n",
              "...      ...     ...     ...     ...  ...       ...       ...       ...       ...\n",
              "41995      0       0       0       0  ...         0         0         0         0\n",
              "41996      1       0       0       0  ...         0         0         0         0\n",
              "41997      7       0       0       0  ...         0         0         0         0\n",
              "41998      6       0       0       0  ...         0         0         0         0\n",
              "41999      9       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[42000 rows x 785 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH_Iq6OQBgLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4b02041a-dee7-4f20-9ca8-5619601f5d71"
      },
      "source": [
        "# データフレームを配列に出来ているか確認\n",
        "train_data = np.array(train_df)\n",
        "test = np.array(test_df)\n",
        "print(train_data)\n",
        "print(test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [7 0 0 ... 0 0 0]\n",
            " [6 0 0 ... 0 0 0]\n",
            " [9 0 0 ... 0 0 0]]\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LiJx_nUCl99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "df439654-0304-400f-90c1-e1c42c52cf3a"
      },
      "source": [
        "# ラベルと目的変数の定義\n",
        "label = train_data[:, 0]\n",
        "train = train_data[:,1:]\n",
        "print(train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pb6o0wbazqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像は1行→28*28にreshapeする必要がある\n",
        "train = train.reshape(len(train), 28, 28, 1)\n",
        "test = test.reshape(len(test), 28, 28, 1)\n",
        "X_train = train\n",
        "X_test = test\n",
        "# print(train)\n",
        "# print(test)\n",
        "# print(train.shape)\n",
        "# print(test.shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5qWYUxvCyTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# クロスバリデーション(トレーニングデータを5つに分割)\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# 多クラス分類のときにクラスのラベルをそのまま推論させない\n",
        "# One-Hot表現に変換し、各クラスに分類される確率を出す。\n",
        "# 0～9の数字のラベルに分類する？\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(label, 10)\n",
        "\n",
        "for train_index, eval_index in kf.split(X_train):\n",
        "    X_tra, X_eval = X_train[train_index], X_train[eval_index]\n",
        "    y_tra, y_eval = y_train[train_index], y_train[eval_index]\n",
        "\n",
        "# データを正規化\n",
        "x_tra = X_tra / 255\n",
        "x_eval = X_eval / 255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aQwlxquhrl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "1d4a8d0b-af84-43d0-cbf3-d90f4c7faaa0"
      },
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "(42000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrYqQTbXE2eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# 画像の表示:imshow(行)→28*28にすればいいのではないか？\n",
        "# plt.imshow(train[300])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnwh2KbxFG9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 必要なライブラリをインポート\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOJIcZ6_V-Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGAiqOHIQ_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "4faebe8b-c8c5-4d34-a27c-18b13f292c01"
      },
      "source": [
        "# モデルを作成：精度を上げるためにはここが一番重要\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 学習のためのモデルを設定\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.002),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 843,658\n",
            "Trainable params: 843,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI5wu9tctG2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ拡張により画像をさらに作成\n",
        "datagen = ImageDataGenerator(\n",
        "        # rotation_range: 整数．画像をランダムに回転する回転範囲．\n",
        "        rotation_range=10,  \n",
        "        # zoom_range: 浮動小数点数または[lower，upper]．ランダムにズームする範囲．浮動小数点数が与えられた場合，[lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "        zoom_range = 0.10,  \n",
        "        # width_shift_range: 浮動小数点数（横幅に対する割合）．ランダムに水平シフトする範囲．\n",
        "        width_shift_range=0.1, \n",
        "        # height_shift_range: 浮動小数点数（縦幅に対する割合）．ランダムに垂直シフトする範囲．\n",
        "        height_shift_range=0.1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzwekmpktMkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像データをImageDataGeneratorに食わせることで画像の水増し\n",
        "datagen.fit(x_tra)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwDuVLL2fncC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習率を返す関数を用意する\n",
        "def lr_schedul(epoch):\n",
        "    x = 0.002\n",
        "    if epoch >= 10:\n",
        "        x = 0.001\n",
        "    if epoch >= 30:\n",
        "        x = 0.0005\n",
        "      if epoch >= 80:\n",
        "        x = 0.0001\n",
        "    return x\n",
        "\n",
        "\n",
        "lr_decay = LearningRateScheduler(\n",
        "    lr_schedul,\n",
        "    # verbose=1で、更新メッセージ表示。0の場合は表示しない\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGx_vz4ez6PX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48e88c3e-6e86-4f24-f9e4-3f61dbb92d72"
      },
      "source": [
        "# 学習\n",
        "result = model.fit_generator(datagen.flow(x_tra, y_tra),\n",
        "          epochs=100,\n",
        "          validation_data=(x_eval, y_eval),\n",
        "          callbacks=[lr_decay]\n",
        "           )\n",
        "\n",
        "print('')\n",
        "# 精度を検証\n",
        "model.evaluate(x_eval, y_eval)\n",
        "\n",
        "print('')\n",
        "# 学習状況のログを表示\n",
        "history = result.history\n",
        "# vars(model.history)['history']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-b7a9be6991e6>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.002.\n",
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 2.1795 - accuracy: 0.2823 - val_loss: 1.6918 - val_accuracy: 0.6602\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.002.\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 1.4572 - accuracy: 0.5437 - val_loss: 0.6467 - val_accuracy: 0.8245\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.002.\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 1.0847 - accuracy: 0.6456 - val_loss: 0.4627 - val_accuracy: 0.8727\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.9224 - accuracy: 0.7045 - val_loss: 0.3941 - val_accuracy: 0.8899\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.8265 - accuracy: 0.7415 - val_loss: 0.3405 - val_accuracy: 0.9092\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.7486 - accuracy: 0.7681 - val_loss: 0.3132 - val_accuracy: 0.9187\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.7123 - accuracy: 0.7798 - val_loss: 0.2931 - val_accuracy: 0.9220\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.6726 - accuracy: 0.7920 - val_loss: 0.2763 - val_accuracy: 0.9280\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.6388 - accuracy: 0.8024 - val_loss: 0.2613 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.6052 - accuracy: 0.8137 - val_loss: 0.2489 - val_accuracy: 0.9321\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.5728 - accuracy: 0.8230 - val_loss: 0.2371 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.5495 - accuracy: 0.8291 - val_loss: 0.2271 - val_accuracy: 0.9388\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.5284 - accuracy: 0.8384 - val_loss: 0.2173 - val_accuracy: 0.9426\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.5003 - accuracy: 0.8477 - val_loss: 0.2098 - val_accuracy: 0.9443\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.4760 - accuracy: 0.8533 - val_loss: 0.2035 - val_accuracy: 0.9457\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.4667 - accuracy: 0.8591 - val_loss: 0.1971 - val_accuracy: 0.9452\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.4506 - accuracy: 0.8617 - val_loss: 0.1922 - val_accuracy: 0.9483\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.4345 - accuracy: 0.8684 - val_loss: 0.1850 - val_accuracy: 0.9498\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.4222 - accuracy: 0.8724 - val_loss: 0.1861 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.4043 - accuracy: 0.8762 - val_loss: 0.1777 - val_accuracy: 0.9502\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3965 - accuracy: 0.8798 - val_loss: 0.1717 - val_accuracy: 0.9513\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3854 - accuracy: 0.8822 - val_loss: 0.1707 - val_accuracy: 0.9521\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.3764 - accuracy: 0.8832 - val_loss: 0.1644 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3658 - accuracy: 0.8893 - val_loss: 0.1608 - val_accuracy: 0.9552\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3534 - accuracy: 0.8929 - val_loss: 0.1575 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.3509 - accuracy: 0.8935 - val_loss: 0.1544 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3393 - accuracy: 0.8945 - val_loss: 0.1552 - val_accuracy: 0.9555\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3366 - accuracy: 0.8987 - val_loss: 0.1489 - val_accuracy: 0.9574\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.3359 - accuracy: 0.8980 - val_loss: 0.1462 - val_accuracy: 0.9601\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3257 - accuracy: 0.9013 - val_loss: 0.1465 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 16s 15ms/step - loss: 0.3160 - accuracy: 0.9025 - val_loss: 0.1411 - val_accuracy: 0.9610\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.3147 - accuracy: 0.9041 - val_loss: 0.1442 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 16s 16ms/step - loss: 0.3015 - accuracy: 0.9075 - val_loss: 0.1375 - val_accuracy: 0.9615\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 19s 18ms/step - loss: 0.3003 - accuracy: 0.9082 - val_loss: 0.1366 - val_accuracy: 0.9614\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.3002 - accuracy: 0.9090 - val_loss: 0.1370 - val_accuracy: 0.9611\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 36/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2950 - accuracy: 0.9101 - val_loss: 0.1347 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 37/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.2927 - accuracy: 0.9112 - val_loss: 0.1317 - val_accuracy: 0.9631\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 38/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2820 - accuracy: 0.9121 - val_loss: 0.1300 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 39/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2800 - accuracy: 0.9142 - val_loss: 0.1254 - val_accuracy: 0.9639\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 40/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2748 - accuracy: 0.9154 - val_loss: 0.1233 - val_accuracy: 0.9648\n",
            "\n",
            "Epoch 00041: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 41/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2744 - accuracy: 0.9170 - val_loss: 0.1262 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00042: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 42/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2723 - accuracy: 0.9163 - val_loss: 0.1245 - val_accuracy: 0.9640\n",
            "\n",
            "Epoch 00043: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 43/100\n",
            "1050/1050 [==============================] - 17s 17ms/step - loss: 0.2678 - accuracy: 0.9198 - val_loss: 0.1218 - val_accuracy: 0.9642\n",
            "\n",
            "Epoch 00044: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 44/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2655 - accuracy: 0.9184 - val_loss: 0.1219 - val_accuracy: 0.9640\n",
            "\n",
            "Epoch 00045: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 45/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2592 - accuracy: 0.9212 - val_loss: 0.1214 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00046: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 46/100\n",
            "1050/1050 [==============================] - 17s 17ms/step - loss: 0.2602 - accuracy: 0.9212 - val_loss: 0.1215 - val_accuracy: 0.9637\n",
            "\n",
            "Epoch 00047: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 47/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2523 - accuracy: 0.9228 - val_loss: 0.1206 - val_accuracy: 0.9645\n",
            "\n",
            "Epoch 00048: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 48/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2498 - accuracy: 0.9234 - val_loss: 0.1150 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00049: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 49/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2380 - accuracy: 0.9278 - val_loss: 0.1130 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00050: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 50/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2492 - accuracy: 0.9238 - val_loss: 0.1158 - val_accuracy: 0.9660\n",
            "\n",
            "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 51/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2460 - accuracy: 0.9246 - val_loss: 0.1124 - val_accuracy: 0.9669\n",
            "\n",
            "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 52/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2416 - accuracy: 0.9257 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
            "\n",
            "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 53/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2418 - accuracy: 0.9261 - val_loss: 0.1079 - val_accuracy: 0.9685\n",
            "\n",
            "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 54/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2393 - accuracy: 0.9265 - val_loss: 0.1183 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 55/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.2348 - accuracy: 0.9278 - val_loss: 0.1121 - val_accuracy: 0.9675\n",
            "\n",
            "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 56/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2313 - accuracy: 0.9292 - val_loss: 0.1052 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 57/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2312 - accuracy: 0.9283 - val_loss: 0.1054 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 58/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2206 - accuracy: 0.9321 - val_loss: 0.1059 - val_accuracy: 0.9690\n",
            "\n",
            "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 59/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2281 - accuracy: 0.9305 - val_loss: 0.1069 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 60/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2238 - accuracy: 0.9319 - val_loss: 0.1045 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 61/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2201 - accuracy: 0.9328 - val_loss: 0.1031 - val_accuracy: 0.9704\n",
            "\n",
            "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 62/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2229 - accuracy: 0.9325 - val_loss: 0.1017 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 63/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2171 - accuracy: 0.9349 - val_loss: 0.1008 - val_accuracy: 0.9712\n",
            "\n",
            "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 64/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2137 - accuracy: 0.9347 - val_loss: 0.1003 - val_accuracy: 0.9710\n",
            "\n",
            "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 65/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2127 - accuracy: 0.9363 - val_loss: 0.0972 - val_accuracy: 0.9724\n",
            "\n",
            "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 66/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2113 - accuracy: 0.9352 - val_loss: 0.0974 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 67/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2186 - accuracy: 0.9321 - val_loss: 0.0990 - val_accuracy: 0.9711\n",
            "\n",
            "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 68/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2117 - accuracy: 0.9355 - val_loss: 0.0979 - val_accuracy: 0.9727\n",
            "\n",
            "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 69/100\n",
            "1050/1050 [==============================] - 21s 20ms/step - loss: 0.2119 - accuracy: 0.9370 - val_loss: 0.0963 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 70/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2124 - accuracy: 0.9340 - val_loss: 0.0943 - val_accuracy: 0.9717\n",
            "\n",
            "Epoch 00071: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 71/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2019 - accuracy: 0.9378 - val_loss: 0.0961 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00072: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 72/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.2035 - accuracy: 0.9374 - val_loss: 0.0916 - val_accuracy: 0.9733\n",
            "\n",
            "Epoch 00073: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 73/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.2044 - accuracy: 0.9371 - val_loss: 0.0933 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00074: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 74/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1983 - accuracy: 0.9385 - val_loss: 0.0942 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00075: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 75/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1972 - accuracy: 0.9394 - val_loss: 0.0969 - val_accuracy: 0.9725\n",
            "\n",
            "Epoch 00076: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 76/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.2015 - accuracy: 0.9375 - val_loss: 0.0956 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00077: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 77/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1984 - accuracy: 0.9392 - val_loss: 0.0888 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00078: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 78/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1947 - accuracy: 0.9399 - val_loss: 0.0904 - val_accuracy: 0.9731\n",
            "\n",
            "Epoch 00079: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 79/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1975 - accuracy: 0.9394 - val_loss: 0.0889 - val_accuracy: 0.9750\n",
            "\n",
            "Epoch 00080: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 80/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1936 - accuracy: 0.9412 - val_loss: 0.0900 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00081: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 81/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1921 - accuracy: 0.9412 - val_loss: 0.0859 - val_accuracy: 0.9752\n",
            "\n",
            "Epoch 00082: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 82/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1896 - accuracy: 0.9422 - val_loss: 0.0859 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00083: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 83/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1884 - accuracy: 0.9429 - val_loss: 0.0866 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00084: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 84/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1859 - accuracy: 0.9434 - val_loss: 0.0855 - val_accuracy: 0.9757\n",
            "\n",
            "Epoch 00085: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 85/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.1833 - accuracy: 0.9422 - val_loss: 0.0872 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00086: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 86/100\n",
            "1050/1050 [==============================] - 17s 17ms/step - loss: 0.1854 - accuracy: 0.9431 - val_loss: 0.0837 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00087: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 87/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1819 - accuracy: 0.9436 - val_loss: 0.0849 - val_accuracy: 0.9758\n",
            "\n",
            "Epoch 00088: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 88/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1818 - accuracy: 0.9451 - val_loss: 0.0856 - val_accuracy: 0.9746\n",
            "\n",
            "Epoch 00089: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 89/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1852 - accuracy: 0.9433 - val_loss: 0.0823 - val_accuracy: 0.9762\n",
            "\n",
            "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 90/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1839 - accuracy: 0.9447 - val_loss: 0.0852 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00091: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 91/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.1781 - accuracy: 0.9455 - val_loss: 0.0821 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00092: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 92/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1822 - accuracy: 0.9451 - val_loss: 0.0830 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00093: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 93/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1773 - accuracy: 0.9456 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00094: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 94/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1785 - accuracy: 0.9455 - val_loss: 0.0827 - val_accuracy: 0.9764\n",
            "\n",
            "Epoch 00095: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 95/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1755 - accuracy: 0.9457 - val_loss: 0.0805 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 96/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1730 - accuracy: 0.9464 - val_loss: 0.0819 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 97/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1734 - accuracy: 0.9472 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
            "\n",
            "Epoch 00098: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 98/100\n",
            "1050/1050 [==============================] - 18s 17ms/step - loss: 0.1740 - accuracy: 0.9471 - val_loss: 0.0799 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00099: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 99/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1700 - accuracy: 0.9473 - val_loss: 0.0804 - val_accuracy: 0.9769\n",
            "\n",
            "Epoch 00100: LearningRateScheduler reducing learning rate to 0.0005.\n",
            "Epoch 100/100\n",
            "1050/1050 [==============================] - 17s 16ms/step - loss: 0.1681 - accuracy: 0.9478 - val_loss: 0.0792 - val_accuracy: 0.9762\n",
            "\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnazXPgGRX7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7d7fd15-db5c-4f36-cca2-824742efd0d6"
      },
      "source": [
        "print(history.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLAevu4e1vsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "86f40291-e3d1-4867-e36b-ddda335c8f53"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 学習曲線を表示する→どうやって表示させるんだっけ？historyをインスタンス化して列名取得じゃダメなの？\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(history['loss'], label='loss')\n",
        "ax1.plot(history['val_loss'], label='val_loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history['accuracy'], label='accuracy')\n",
        "ax2.plot(history['val_accuracy'], label='val_accuracy')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2uzlaXb2dUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "42b48fb8-1337-4d3a-ca7f-4cbfa5eae413"
      },
      "source": [
        "# テストデータの予測\n",
        "results = model.predict(test)\n",
        "# カテゴリー分類されたテストデータの最大値のインデックス(右から順に数えて何番目かを返す)\n",
        "results = np.argmax(results,axis = 1)\n",
        "# npの配列のままなので、データフレームの形に直して名前を付ける\n",
        "results = pd.Series(results, name=\"Label\")\n",
        "# 一応できているか確認\n",
        "print(results)\n",
        "print(results.shape)\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "submission.to_csv(\"CNN_submission.csv\",index=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        2\n",
            "1        0\n",
            "2        9\n",
            "3        9\n",
            "4        3\n",
            "        ..\n",
            "27995    9\n",
            "27996    7\n",
            "27997    3\n",
            "27998    9\n",
            "27999    2\n",
            "Name: Label, Length: 28000, dtype: int64\n",
            "(28000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXJtBVjwRjJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "76d10c03-c116-47a8-d58b-4483aed4a079"
      },
      "source": [
        "sub_df = pd.read_csv('CNN_submission.csv')\n",
        "print(sub_df.shape)\n",
        "print(sub_df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 2)\n",
            "       ImageId  Label\n",
            "0            1      2\n",
            "1            2      0\n",
            "2            3      9\n",
            "3            4      9\n",
            "4            5      3\n",
            "...        ...    ...\n",
            "27995    27996      9\n",
            "27996    27997      7\n",
            "27997    27998      3\n",
            "27998    27999      9\n",
            "27999    28000      2\n",
            "\n",
            "[28000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL8J1vNonz8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}